[TOC]

# 关系抽取的做法
## 基于规则
## 基于知识图谱
## 深度学习方法
### pipeline式
* 关系分类的实体抽取分成两个task进行，分别计算loss，互不影响
* 做分类时可以将NER的信息作为特征补充输入
    * 例如，将NER的实体加入到文本输入 `[CLS] + 句子 + [SEP] + 实体1 + [SEP] + 实体2` 
    * 可以标记输入中的实体，**输出层不只用`[CLS]`的向量，也加入实体最后一层的隐层特征表示**

### joint式
* 关系实体合并成一个multi-task，统一计算loss

![join做法](https://pic4.zhimg.com/80/v2-24aefcc56ec9b52f51a6955cca176263_720w.jpg)

https://arxiv.org/pdf/1908.07721.pdf

* 可以用attention mask实现（关注实体）


# 命名实体识别
## BERT+CRF
* BERT输入为 [CLS] + 句子 + [SEP]
* 通过BERT获取**隐层输出`get_sequence_output()`**，并通过全连接层转换为emission_prob matrix ，**维度`[batch_size,seq_length,num_tags]`**
* 隐层输出作为`crf`输入，并且创建`transition matrix`，调用`tf.contrib.crf.ctf_log_likelihood`计算损失