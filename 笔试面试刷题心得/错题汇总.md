本文档记录刷题过程中做错的一些题目,并将其分类，以便于以后复习。
[toc]

# 机器学习基础知识
1. **增加以下哪些超参数可能导致随机森林模型过拟合数据？**
```
    1. 决策树的数量；
    2. 决策树的深度；
    3. 学习率。
    
    答案: 2
```


2. **在线性回归中使用正则项，你发现解的不少coefficient都是0，则这个正则项可能是：**
```
1. L0-norm 
2. L1-norm
3. L2-norm

答案：1、2 L0-norm为向量中非零元素的个数
```

3. **当训练样本数量趋向于无穷大时，在该数据集上训练的模型变化趋势，对于其描述正确的是 ：**
```
1. 偏差(bias)变小
2. 偏差变大
3. 偏差不变
4. 不确定

答案： 3，模型收敛后偏差趋向不变
```
4. **随机变量`$X \sim N(1,2),Y \sim N(3,5)$`，则`$X+Y \sim$`**
```
1. N(4,7)
2. N(4,\sqrt 2 + \sqrt 5)
3. N(1 + \sqrt 3 ,7)
4. 不确定

答案 ： 4 ,通过边缘概率分布不能确定联合概率分布 
```
5. **若将KNN看成是kernel method的一种实现， 则kernel函数为**<br/>

![](https://uploadfiles.nowcoder.com/images/20190219/301499_1550567692105_5520F725D504DC6D8E7988AB60887D7A)<br/>
![](https://uploadfiles.nowcoder.com/images/20190219/301499_1550567748421_D5C045191B1C7123C9186D38C080736D)<br/>
![](https://uploadfiles.nowcoder.com/images/20190219/301499_1550567777190_66F1670D2A78F7435844BEE8BF56F3B4)<br/>
![](https://uploadfiles.nowcoder.com/images/20190219/301499_1550567794540_F59D30E1213C3D5B815889ACB7D0EDD5)<br/>

答案 ：B


6. **下列不是SVM的常用核函数的是？**
```
1. 多项式核函数
2. sigmoid核函数
3. 径向基核函数
4. logistic核函数

答案：4.
```

* SVM常见核函数:
    + q次多项式核
    + 径向基函数
    + S型函数(Sigmoid)

7. **下列描述中错误的是？**
```
1. 函数在某点的梯度方向与取得最大方向导数的方向一致。
2. 在等式约束条件下，约束的梯度向量与目标函数的梯度向量在最优解处一定平行。
3. KKT条件是强对偶成立的充要条件。
4. 函数在某点的梯度的模为方向导数的最大值。

答案：3.
```
&emsp;&emsp;KKT条件是强对偶性成立的必要条件，特别的，当原问题是凸优化问题时，KKT条件就是充要条件。



8. **关于线性规划的算法复杂度 以下哪些是正确的？**
```
1. simplex在多项式复杂度的时间内可以解决线性规划问题
2. simplex不是多项式复杂度，而且线性规划的问题不可以在多项式时间内求解
3. 线性规划的问题可以在多项式时间内求解，但是simplex不是多项式复杂度
4. 因为线性规划的可行域总是凸集，所以simplex算法才能在多项式时间复杂度内解决线性规划问题

答案：3.
```
9. **在相同样本量下，重复抽样与不重复抽样的抽样平均误差大小关系是？**
```
1. 二者相同
2. 重复抽样误差大
3. 不重复抽样误差大
4. 不确定

答案： 2.
```
![](https://uploadfiles.nowcoder.com/images/20190505/311516697_1557063164347_5822A72F4E1B5BC2561C96675C10600A)

10. **以下关于K近邻(KNN)算法的说法中正确的是?**
```
1. KNN算法可以用来解决回归问题
2 .随着K值的增大，决策边界(decision boundary)会越来越光滑
3. KNN算法适合解决高维稀疏数据上的问题
4. 相对3近邻模型而言，1近邻模型的bias更大，variance更小

答案:1. 2. K为1时方差更大，偏差不一定，容易过拟合，K太大时偏差大
```

11. **下列关于特征选择方法中，描述正确的是**
```
1. 传统交叉熵只考虑了特征与类别之间的相关性，而忽略了特征项在类内和类间分布的均匀程度。
2. 互信息筛选特征的方法受稀有特征的影响比较大
3. 信息增益筛选特征倾向于特征值比较多的特征
4. 皮尔逊相关系数计算时，方差均为0时，相关性最大

答案: 4.  当方差为0的时候，相关系数为0.
```

12. **关于准确率、召回率和f1-score，以下错误的是：**
```
1. 准确率为TP/(TP+FP)
2. 召回率为TP/(TP+FN)
3. f1-score为2TP/(2TP+FP+FN)
4. f1-score为准确率*召回率/(准确率+召回率)
```

![](https://uploadfiles.nowcoder.com/files/20181227/545691869_1545876249037_4610b912c8fcc3ceb409adb89045d688d53f206b.jpg)


13. **以下哪些算法可以通过无监督学习方式进行训练？**
```
1. SVM
2. K-Medoids
3. 决策树
4. RBM
5. GAN

答案 : 2. 4. 5. RBM（受限玻尔兹曼机）也可以通过无监督学习训练
```


14. **以下哪个不属于过拟合解决方式**
```
1. bagging/boosting
2. batch normalization
3. L2范式
4. cross validation

答案: 2.  交叉验证的作用是建立模型和验证模型，对样本数进行切割，组成不同的训练集和测试集。
```


15. **以下哪些分类器是线性分类器**
```
1. 朴素贝叶斯
2. SVM
3. 逻辑回归
4. 感知机
5. XGBoost
```
* 线性分类器：模型是参数的线性函数，分类平面是（超）平面；
* 非线性分类器：模型分界面可以是曲面或者超平面的组合。
* 典型的线性分类器有感知机，LDA，逻辑斯特回归，SVM（线性核）；
* 典型的非线性分类器有朴素贝叶斯（有文章说这个本质是线性的，http://dataunion.org/12344.html），kNN，决策树，SVM（非线性核）


16. **关于随机森林描述正确的是：**
```
1. 随机森林可以降低预测方差
2. 随机森林可以降低预测偏差
3. 随机森林可以降低噪音
4. 以上全部

错选:4.
答案:1.
```
随机森林采用bagging的集成思想，可以降低方差，对于boosting模型可以降低偏差

17. **在机器学习的特征选择过程中，可以用到的方法有**
```
1. 卡方
2. 信息增益
3. 交叉熵
4. 互信息

错选:2. 4.
正确:1. 2. 3. 4.
```

在文本分类中，首先要对数据进行特征提取，特征提取中又分为特征选择和特征抽取两大类，在特征选择算法中有**互信息，文档频率，信息增益，卡方检验以及期望交叉熵**。
* 期望交叉熵，以文本分类为例子，期望交叉熵用来度量一个词对于整体的重要程度。
* 在ID3决策树中，也使用信息增益作为特征选择的方法，在C4.5决策树中，使用信息增益比作为特征选择的方法，在CART中，使用基尼指数作为特征选择的方法
* 链接：https://www.nowcoder.com/questionTerminal/bacc960e371c496e9e1ff9b7233a5b0a?orderByHotValue=2&mutiTagIds=631&page=1&onlyReference=false

18. **关于下列机器学习理论上的各种描述，请选择下列正确的选项**
```
1. 逻辑斯提回归的常用损失函数其实本质是一种相对熵度量
2. 核方法可以简化再机器学习中高维映射的运算
3. 随机梯度下降方法可以得到理论上的最优解
4. 剪枝是防止决策树模型过拟合的一种常见方法

错选:2. 3. 4.
答案:2. 4.
```
19. **深度学习中的不同最优化方式，如SGD，ADAM下列说法中正确的是**
```
1. 在实际场景下，应尽量使用ADAM，避免使用SGD
2. 同样的初始学习率情况下，ADAM的收敛速度总是快于SGD方法
3. 相同超参数数量情况下，比起自适应的学习率调整方式，SGD加手动调节通常会取得更好效果
4. 同样的初始学习率情况下，ADAM比SGD容易过拟合

错选: 2.
答案: 3.
```

20. **以下哪个方法不能用来降维：**
```
1. PCA
2. IsoMap
3. LLE
4. LVW

错选: 2.
答案: 4.
```
* PCA:主成分分析
* LLE：局部线性嵌入
* IsoMap：等度量映射
* LVW：拉斯维加斯**特征选择算法**


21. **以下关于kNN的说法中，错误的是：**
```
1. 一般使用投票法进行分类任务
2. kNN属于懒惰学习
3. kNN训练时间普遍偏长
4. 距离计算方法不同，效果也可能有显著差别

错选: 1.
答案: 3.
```
* KNN有训练集做标签但无需训练过程

22. **下列关于随机森林和GBDT的说法正确的是：**
```
1. 都是一种Boosting方法
2. 组成随机森林的树可以分类树也可以是回归树，而GBDT只由回归树组成
3. 随机森林的训练属于属性扰动，不属于样本扰动
4. 随机森林对异常值敏感，而GBDT对异常值不敏感

错选：3.
答案：4.
```
* GDBT是boosting算法，随机森零是Bagging算法
* GDBT是样本扰动，随机森林是样本扰动和属性扰动。
* GDBT对异常值敏感，随机森林对异常值不敏感。
* gbdt 无论用于分类还是回归一直都是使用的CART 回归树。


23. **给定下列样本的标签和预测值，则以下(A,B,C)三分类预测的micro F1 score和macro F1 score分别为：**
* 样本编号
* 1	2	3	4	5	6	7	8	9
* 样本标签
* A	A	A	B	B	B	B	C	C
* 样本预测 
* A	A	B	C	B	B	C	C	C

```
1. 2/3，4/7
2. 214/315，2/3
3. 2/3，214/315
4. 4/7，2/3

答案: 3.
```

24. **下列关于Bootstrap采样说法正确的是**
```
1. 从总的 M 个特征中，有放回地抽取 m 个特征（m < M）
2. 从总的 M 个特征中，无放回地抽取 m 个特征（m < M）
3. 从总的 N 个样本中，有放回地抽取 n 个样本（n < N）
4. 从总的 N 个样本中，无放回地抽取 n 个样本（n < N）

错选：4.
答案：3.
```
25. **下列聚类算法，需要使用样本label信息的算法是**
```
1. K-Means
2. DBSCAN
3. Learning Vector Quantization
4. 高斯混合聚类

答案:3.
```
* 学习矢量量化(Learning Vector Quantization,LVQ),是一种用于模式分类的有监督的学习算法,也是一种结构简单、功能强大的有监督的神经网络分类算法
* DBSCAN(Density-Based Spatial Clustering of Applications with Noise)是一个比较有代表性的基于密度的聚类算法

26. **以下哪个关于术语的描述是正确的**
```
1. 数值计算中, overflow通常是指待存储数据超过指定类型变量能表示的范围的上界
2. 数值计算中, underflow通常是指待存储变量无限接近于0而指定类型变量精度不足
3. 机器学习中, overfitting是因为模型训练数据太少
4. 机器学习中, underfitting往往是因为模型比较弱, 使用bagging能有效帮助降低预估偏差

错选:3.
答案:2.
```

* 数值计算中, overflow通常是指待存储数据超级无敌大  没边界

27. **以下关于ROC曲线和AUC概念错误的是**
```
1. AUC是ROC曲线和x轴围成的面积
2. AUC取值范围在0.5~1之间
3. AUC可以用来判断模型的优劣
4. ROC曲线是FPR和TPR的点连成的线

错选：1.
答案：2. 一般情况下 AUC 取0.5~1
```
28. **我们想在大数据集上训练决策树, 为了使用较少时间, 我们可以**
```
1. 增加树的深度
2. 增加学习率 (learning rate)
3. 减少树的深度
4. 减少树的数量

错选：2.
答案：3.
```
29. **对于线性回归，我们应该有以下哪些假设**  

1.找到离群点很重要, 因为线性回归对离群点很敏感 

2.线性回归要求所有变量必须符合正态分布

3.线性回归假设数据没有多重线性相关性

```
1. 1
2. 2,3
3. 1,2,3
4. 其他都不是

错选：3.
答案：1.
```


30. **影响聚类算法效果的主要因素有（）**
```
1. 已知类别的样本质量
2. 分类准则
3. 特征选取
4. 模式相似性测度

答案:2. 3. 4.
```





# 深度学习基础知识
1. **输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为**

```
1. 95
2. 96
3. 97
4. 98

答案 : 97.
```

* 图像卷积后尺寸计算公式
    * 输入图片大小W*W
    * Filter大小F*F
    * 步长S
    * Padding的像素数P


* N = （W-F+2P）/ S+1 ，输出图片大小为 N*N。 

2. **假设我们有一个5层的神经网络，这个神经网络在使用一个4GB显存显卡时需要花费3个小时来完成训练。而在测试过程中，单个数据需要花费2秒的时间。 如果我们现在把架构变换一下，当评分是0.2和0.3时，分别在第2层和第4层添加Dropout，那么新架构的测试所用时间会变为多少？**

```
1. 少于2s
2. 大于2s
3. 仍是2s
4. 说不准

答案: 3. dropout会增加训练时间，但是不会增加测试时间。
```

3. 


# 编程算法基础（时间复杂度计算等）
1. **完全二叉树共有100结点，该二叉树有多少个叶子结点？**
```
1. 49
2. 50
3. 51
4. 52

答案 : 2 
```
&emsp;&emsp;完全二叉树，当节点数为偶数时，叶子节点个数为n/2，当节点数为奇数时，叶子节点个数为(n+1)/2


2. **求一个长度为n的无序数组的中位数，期望复杂度和最坏复杂度最优分别可以做到**
```
1. O(1),O(n)
2. O(n),O(n)
3. O(n),O(nlogn)
4. O(nlogn),O(nlogn)

答案：3.
```

3.**若一个递归函数的规模函数T(n) = T(n-2) + (n^2)/3，则其算法的时间复杂度为:**
```
1. O(n^2)
2. O(n^2 log(n))
3. O(n^3)
4. O(n^3 log(n))

答案: 3.
```

* **算数级数**：与末项平方同阶:<br/>
`$T(n) = 1+2+3+..+n = n(n+1)/2 = O(n^2)$`<br/>

* **幂方级数**：比幂次高出一阶:<br/>
`$T_2(n) = 1^2+2^2+3^2+..+n^2 = n(n+1)(2n+1)/6 = O(n^3)$`<br/>
`$T_3(n) = 1^3+2^3+3^3+..+n^3 = n^2(n+1)^2/4 = O(n^4)$`<br/>
* **几何级数**: 与末项同阶:<br/>
`$T_a(n) = a^0+a^1+a^2+..+a^n = (a^{(n+1)}-1)/(a-1) = O(a^n)$`<br/>
* **调和级数**：<br/>
`$h(n) = 1+ 1/2 + 1/3 + ... + 1/n = O(logn)$`<br/>
* **对数级数**：<br/>
`$log1 + log2 + log3 + log4 + ... + logn = log(n!) = O(nlogn)$`<br/>



4. **下列哪个不属于CRF模型相对于HMM和MEMM模型的优势？**
```
1. 特征灵活
2. 判别式模型
3. 容纳上下文信息
4. 全局最优

答案：2. CRF取消了观测独立假设和一阶马可夫假设。
```

5. **以下关于贪心算法说法不正确的是:**
```
1. 待求解问题必须可以分解为若干子问题
2. 每一子问题, 都可以得到局部最优解
3. 解决问题通常自底向上
4. Dijkstra单源最短路径算法是贪心算法
```
* 贪心算法往往是这种自顶向下的设计，先做出一个选择，然后再求解下一个问题，而不是自底向上解出许多子问题，然后再做出选择。

6. **下列最短路径算法的叙述中正确的是（）**
```
1. Dijkstra算法通常用于求每一对顶点间的最短路径；
2. Dijkstra算法不允许图中带有负权值的边，而Floyd算法则可以适用；
3. Floyd算法通常用于求某一顶点到其他各顶点的最短路径；
4. Floyd算法允许有包含负权值的边组成的回路，而Dijkstra算法不允许；

答案: 2. 
```
* Dijkstra不能处理负权图,Flyod能处理负权图
* Dijkstra处理单源最短路径
* Flyod是处理多源最短路径


6. **在对问题的解空间树进行搜索的方法中，一个结点有多次机会成为活结点的是：（）**
```
1. 动态规划
2. 回溯法
3. 分支限界法
4. 回溯法和分支限界法

答案: 2. 分支限界法，类似于树的BFS算法，维护一个队列，每当pop出一个element时，把符合标准并且和这个元素相连的元素入队
```

7. **用俩个栈模拟实现一个队列，如果栈的容量分别是O和P(O>P),那么模拟实现的队列最大容量是多少？**
```
1. O+P
2. 2O+1
3. 2P+1
4. 2O-1

答案：3. 首先将1,...,P元素入栈A，栈底到栈顶的顺序为P,....,1，然后A栈弹出，依次入栈B，然后输出1,....,P。之后将P+1,.....,2P+1元素入栈A，然后依次弹出2P+1,.....P+2共n个元素，然后依次入栈B，栈A弹出输出P+1，栈B依次弹出P+2...等，队列容量为2P+1.
```

8. **栈的特点是先进后出。栈底至栈顶依次存放元素A、B、C、D， 在第五个元素E入栈前，栈中元素可以出栈，则出栈序列可能是：（）**
```
1. DCBEA
2. DEBCA
3. DBCEA
4. DCAEB

答案：1. 由于栈是先入后出 E入栈之前 栈中的元素都可以出栈
所以E的位置不定，但是其他元素出栈顺序必须按顺序出栈。
```


9. **下列叙述中，有关线性链表叙述正确的是（）**
```
1. 线性链表中的表头元素一定存储在其他元素的前面
2. 线性链表中的各元素在存储空间中的位置不一定是连续的，但表头元素一定存储在其他元素的前面
3. 线性链表中的各元素在存储空间中的位置必须是连续的
4. 线性链表中的各元素在存储空间中的位置不一定是连续的，且各元素的存储顺序也是任意的

答案：4. 
链表的特点就是不一定按照顺序存储，无论是存储的空间位置还是存储顺序都是任意的
```
10. **包含 2019 个节点、先序遍历序列与中序遍历序列相同的二叉树共有( )棵。** 
```
1. 0
2. 1
3. 2
4. 2019

答案：1. 除了叶子节点每个节点都只有右子树才符合题意
```
![](https://www.nowcoder.com/equation?tex=1%5C%5C%0A%5Cquad%5Csearrow%5C%5C%0A%5Cqquad%5Cquad2%5C%5C%0A%5Cqquad%5Cqquad%5Cquad%5Csearrow%5C%5C%0A%5Cqquad%5Cqquad%5Cqquad%5Cquad...%5C%5C%0A%5Cqquad%5Cqquad%5Cqquad%5Cqquad%5Cquad%5Csearrow%5C%5C%0A%5Cqquad%5Cqquad%5Cqquad%5Cqquad%5Cqquad%5C%3B2019)


# 操作系统与数据库
1. **同一进程下的多个线程可以共享哪一种资源**

```
1. stack
2. data section
3. register set
4. thread ID


答案 : 2. data section
```

2. **下列关于数据库事务ACID特性的说法不正确的是？**
```
1. A指的是原子性，即事务中的所有操作要么全部成功，要么全部失败
2. C指的是一致性，即系统的状态只能是事务前的状态，或者是事务成功后的状态，而不会出现任何不一致的中间状态
3. I指的是可用性，即数据库系统要为事务执行提供尽可能高的可用性，确保大部分事务可以成功的被执行
4. D指的是持久性，即事务成功后即使发生机器断电，也可以恢复到事务成功后的状态

答案：3.
```
3. **在Linux上，对于多进程，子进程继承了父进程的下列哪些？**
```
1、进程地址空间
2、共享内存
3、信号掩码
4、已打开的文件描述符
5、其他选项都不是

答案： 2.3.4 
```
&emsp;&emsp;
**子进程继承父进程**<br/>
-  用户号UIDs和用户组号GIDs
-  环境Environment
-  堆栈 
-  共享内存 
-  打开文件的描述符 
-  执行时关闭（Close-on-exec）标志 
-  信号（Signal）控制设定 
-  进程组号
-  当前工作目录 
-  根目录
-  文件方式创建屏蔽字 
-  资源限制 
-  控制终端

&emsp;&emsp;
**子进程独有**<br/>
- 进程号PID 
- 不同的父进程号 
- 自己的文件描述符和目录流的拷贝 
- 子进程不继承父进程的进程正文（text），数据和其他锁定内存（memory locks） 
- 不继承异步输入和输出

**父进程和子进程拥有独立的地址空间和PID参数**
4. **SQL的drop/delete/truncate都表示删除，其中哪个是在事务提交后才生效的？**
```
1. drop
2. delete
3. truncate
4. 都可以

错选:3.
答案:2.
```

5. **SQL查询中，只有满足联接条件的记录才包含在查询结果中，这种联接为____。** 
```
1. 左联接
2. 右联接
3. 内部联接
4. 完全联接

答案: 2.
```
&emsp;&emsp;
* Inner join: 又称为等值连接，只选择满足条件的行
* Outer join: 外连接会保存没有关联的行
    * left outer join:保存左边表的所有行
    * right outer join：保存右边表的所有行
    * full join: 保存所有没有关联的行，当某行在另一个表中没有匹配行时，则另一个表的列为空值
5. **下列对于数据库索引的说法一定是错误的:**

```
1. 对于只有很少数据值的列，不应该创建索引
2. 全表扫描不一定比使用索引的执行效率低
3. 索引不会影响表的删除操作效率
4. 主键一定包含一个唯一索引

答案: 3. 如果要删除的字段与建立索引的字段相同，删除效率会提高。如果不同效率会降低。
```
6. **TCP 三次握手的过程，accept 发生在三次握手哪个阶段？**
```
1. 第一次握手
2. 第二次握手
3. 第三次握手
4. 三次握手后

答案:4.
```
&emsp;&emsp;TCP三次握手过程
* 第一次握手：客户端发送SYN包(SYN=j)到服务器
* 第二次握手：服务器收到SYN包，必须确认客户的SYN（ACK=j+1），同时自己也发送一个ASK包（ask=k）
* 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1)
* 三次握手完成后，客户端和服务器就建立了TCP连接。这是可以调用accept函数获得此连接。

7. 以下http状态码中哪一个是永久重定向？
```
1. 301
2. 302
3. 303
4. 307
```
&emsp;&emsp;常用状态码:
* 1XX：通知
* 2XX：成功
* 3XX：重定向
* 4XX：客户端错误
* 5XX：服务端错误

8.**以下哪个不是产生死锁的必要条件？**
```
1. 互斥条件：一个资源每次只能被一个进程使用
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放
3. 先来先服务条件：多个进程在等待同一资源时，资源将优先分配给先请求者
4. 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系

答案：3.
```
&emsp;&emsp;死锁产生的4个必要条件
* 互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
* 占有且等待：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
* 不可抢占：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
* 循环等待：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。

9. **数字证书不包含（   ）。**
```
1. 颁发机构的名称
2. 证书持有者的私有密钥信息
3. 证书的有效期
4. CA签发证书时所使用的签名算法
```
10. **在关系数据库中，建立数据库表时，将年龄字段值限制在0～18岁之间的这种约束属于___。**
```
1. 实体完整性约束
2. 参照完整性约束
3. 域完整性约束
4. 视觉完整性约束

答案: 3.
```
* 实体完整性：以主码作为唯一性标识，且主属性不能取空值
* 参照完整性：若属性F是基本关系R的外码，它与基本关系S的主码K相对应，则外码必须取空值或者等于S中某个元组的主码值 任何关系数据库都应该支持实体完整性和参照完整性
* 用户定义完整性（域完整性）：不同的关系数据库系统其应用环境的不同，往往还需要一些特殊的条件，用户定义的完整性就是指针对某一具体关系数据库的约束条件，它反映某一具体应用所涉及的数据必须满足的语义要求。
* 关键字完整性：这不是用户自定义的约束，而是默认的，比如，某个字段设置为了date类型，那么该列的值就必须是date类型，比如，某个字段设置为char(64),说明该列值最多保存64个字符（注意是字符，不是字节，这点面试题可能会问到varchar，和char区别）。当我们存放的字符数多于64，就会自动截取64个字符。


11. **关系型数据库创建表都有主键。以下对主键描述正确的是：**
```
1. 主键是唯一索引，唯一索引也是主键
2. 主键是一种特殊的唯一性索引，只可以是聚集索引
3. 主键是唯一、不为空值的列
4. 对于聚集索引来说，创建主键时，不会自动创建主键的聚集索引

答案：3. 主键索引是唯一索引的一种特殊类型，两者有区别，比如逐渐索引不能为空，唯一索引可以。
```

12. **JVM内存不包含如下哪个部分( )**
```
1. Stacks
2. PC寄存器
3. Heap
4. Heap Frame
```
JVM内存五大区域
![](https://uploadfiles.nowcoder.com/images/20190606/291053_1559812298987_4E467FB794A7AF7967F62555B4F0B6A6)

13. **下列哪些操作会使线程释放锁资源？**:
```
1. sleep()
2. wait()
3. join()
4. yield()

答案: 2. 3. 
```

14. **java8中，下面哪个类用到了解决哈希冲突的开放定址法 **
```
1. LinkedHashSet
2. HashMap
3. ThreadLocal
4. TreeMap

答案：3. 4. threadlocalmap使用开放定址法解决haah冲突，hashmap使用链地址法解决hash冲突
```

15. **设计模式可以分为创建型、结构型、行为型几种，以下属于创建模式的是？**
```
1. 职责链模式
2. 装饰模式
3. 单例模式
4. 观察者模式

答案：3.
```
* 创建型模式：单例模式、抽象工厂模式、建造者模式、工厂模式、原型模式。
* 结构型模式：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、***模式。
* 行为型模式：模版方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式、状态模式、策略模式、职责链模式(责任链模式)、访问者模式。

16. **以下关于进程和线程的说法中正确的是?**
```
1. 进程是对一段正在执行的程序的抽象
2. 进程是操作系统的最小调度单元
3. 不同的线程之间既不共享程序计数器也不共享栈
4. 若一个线程A打开了一个文件F并对其拥有读权限，则与其在同一进程下的另一线程B也可以对F进行读操作

答案: 1. 3. 4.
```

17. **一个进程的地址空间中不含下列哪一项？**
```
1. 局部变量
2. 函数调用的参数
3. 函数调用的返回值
4. 子进程的pid


答案： D
```

18. **Hadoop有哪些运行模式？**
```
1. 独立/单机运行
2. 伪分布式运行
3. 集群分布式运行
4. 中心化运行

答案:1. 2. 3.
```
19. 




# NLP
1. **下列关于词向量说法错误的是？**
```
1. Skip-gram训练时预测上下文
2. CBoW相比Skip-gram训练时间更长
3. GloVe使用了全局统计特征
4. GloVe使用了局部上下文特征

答案： 2. 
```
2. **一份数据包含N个文档，其中一个文档中共有T个词，某个词出现的次数为K次，这个词在N/3个文档中出现，那么TF和IDF的乘积为？**
```
1. KT * log(3)
2. K * log(3) / T
3. K * log(3) / K
4. K / (log(3) * T)

答案 : 2. 
```

TF-IDF 为 `词频-逆文本频率`
![](https://img-blog.csdn.net/20180806135836378?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW9tZW5nc3p1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
![](https://img-blog.csdn.net/20180806140023860?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW9tZW5nc3p1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

3. **因为文本数据在可用的数据中是非常无结构的，它内部会包含很多不同类型的噪点，所以要做数据预处理。以下不是自然语言数据预处理过程的是：**
```
1. 词汇规范化
2. 词汇关系统一化
3. 对象标准化
4. 噪声移除
```

4. 

# CV

1. **对于视频编码中的B帧，以下说法不正确的是？**
```
1. 可以同时使用过去和未来的帧作为运动预测的参考帧
2. 可以提升运动预测的准确度
3. 可以降低解码延时
4. 可以提高压缩性能
```

2. **关于颜色空间，下列说法正确的有？**
```
1. 24位RGB真彩色可以表示多达2^24种颜色
2. lab颜色空间和RGB颜色空间等价
3. CMYK颜色空间和RGB颜色空间等价
4. Alpha通道通常表示亮度

错选: 1. 2.
答案: 1. 3.
```

3. **图像有很多种颜色空间，比如RGB,HSV,LAB等。请描述一下这RGB和LAB主要的差异。**

RGB是以三基色相加组合而成的颜色系统，LAB空间是基于人眼识别的颜色系统。在LAB空间中，颜色距离更合理，距离大小能更好的反映颜色是否相近。

4. **尺寸为224×224的RGB图像，输入如图所示的卷积神经网络（每层标记：输出通道数×长×宽；s:stride; d:dilation），输出层感受野大小是**
![](https://uploadfiles.nowcoder.com/images/20190710/314009_1562729543860_CED8FE28C12BC50CA4180687F3B82FED)

答案：55
感受野计算的递推公式 `RF(n) = (RF(n-1)-1) * stride + (dilation-1)*kernel_size + 1`，其中RF(0) = 1,即初始一个像素的感受野，感受野的计算是特征图尺寸计算的逆过程，因此，从输出开始开始计算，故有：

5. 

