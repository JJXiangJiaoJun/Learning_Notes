[TOC]
# GPT、BERT、XLNet有什么区别，为什么选择BERT
* GPT、BERT基础的结构都是Transformer，XLNet的基础结构是Transformer-XL，GPT是单向的语言模型，BERT中提出了Masked Language Model改进成了双向语言模型，而XLNet针对BERT Masked Language Model引入的预测训练阶段不一致以及对超长文本处理效果不好进行了改进，采用的是改进的自回归模型
* BERT是GPT的改进，并且有开源的官方中文模型，XLNet当时没有开源的中文模型，所以选择了BERT作为初版大模型。

# 如果不用attention，使用什么方法可以达到注意某一个词的效果
* 对query进行预处理，分词，可以提取出词语的一些统计特征比如tfidf（通过tfidf对词进行排序）
* 可以考虑模型集成，将BERT输出作为一个隐式表征
* query时效性实体词识别，可以加入图特征等等
* 难以解决的可以考虑用规则匹配

# 如何解决长冷query办法
* query改写
* 加关键词
* 加tag
* query推荐
* **召回上的处理**
    * 向量召回
    * query改写，使用生成式技术
    * 加tag
* **排序上处理**
    * 使用深度特征和文本特征
    * 加关键词，label增强
    * query意图理解
    * 网页标签匹配

# query语义改写
* **问题背景**
    * 商品检索的主要的问题还是在于用户query和商品描述之间存在GAP，特别是中长尾query
        * 多种描述：划痕笔/补漆笔/修补笔/点漆笔
        * 信息冗余:   冰箱温控器温度控制==冰箱温控器
        * 属性检索： 118冰箱、60寸液晶电视机4k高清智能60曲面
        * 宽泛意图： 超美吊灯、大容量冰箱
* **所做工作**
    * 向量相似查找
        * 1.对候选query集合进行kmeans聚类成C个簇
        * 2.遍历C个簇中心查找余弦距离最近的topM个类
        * 3.然后遍历topM个簇中的点获取topK个相似
    * 基于词库
    * 基于拼音
    * 基于N-gram
    * 基于编辑距离

# 常见的召回策略
* 基于内容匹配的召回（根据用户标签）
* 基于协同过滤的召回

# 搜索中碰到新出现的词汇怎么办
* 同义词表查询
* 向量召回

# 数据样本是从哪里来的，标注来自于哪里？
* 通过伪反馈生成，伪反馈模型是一个树模型,模型训练的是小样本的标注数据，对线上query打分，根据分值对数据进行标注，分值-3到-2之间为负例，大于-1为正例，从中随机抽出2KW作为训练样本，正负比例为1:1
* 伪反馈模型是查询索引之后根据召回结果里的时效性样本分布来判断，需要依赖很多

# 时效性触发模型的作用
* 在query查询索引之前，判断query是否具有时效性，并根据这个判断调整查询索引和索引算分的逻辑

# 蒸馏前后的时延降低程度
* Query Process整体的延迟要求是10MS以内
* 12层BERT延时在50MS以上，4层BERT延时在5MS左右，TextCNN延时在2MS左右

# query Process有哪些过程
* query分析，切词
* NER,Tagging,Weighting
* query分类，同义词扩充
* 相关性，时效性，色情，意图分析等

# QPS和Latency的关系
* 当机器资源有限时，QPS和Latency成反比
* 如果降低Latency的成本比较高，我们可以通过增加机器来提高QPS
* 本质上需要找到机器数量和Latency的一个平衡点

# 需求时间敏感度
* 手机报价
* 车票、机票
* 今日气温
* 时刻表


# 描述不完整query如何优化
* 有时候query的意图是手机报价，但是输入只有一个`P30、S6`这种很可能不知道是什么意思，可以用前缀树进行关键词识别，比如构建字典`华为：P30、Mate、荣耀，OPPO：a6`等，