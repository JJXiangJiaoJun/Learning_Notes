[TOC]
# 为什么不使用MIX
* 传统模型存在缺点，非常容易过拟合，对数据集依赖大，举例：假如训练集中大量label的句子对，都出现了“血糖”这个词语，那么很有可能学习出来的模型就会认为只要句子中含有“血糖”，那么标签就极有可能为1，而偏离了我们需要考虑的语义特性，

# 优化
* 将BERT作为一个特征
* 添加图特征，入度出度，pageRank等
* 交互特征编辑距离等

# Pointwise、Pairwise、Listwise
* **Pointwise**
    * 以单个文档作为训练样本，把排序问题当做一个分类问题无法学习到偏序关系 **（只关心当前文档是否相关，可以用于召回）**
* **Pairwise**
    * 输入的是一个query下的一对有偏序关系文档
        * Pairwise考虑了两个文档的先后顺序，却没有考虑文档出现在搜索列表中的位置，比如说排在最前面的几个文档更为重要 **（关心两个文档的偏序关系，用于排序）**
* **Listwise**
    * 将某个query下的所有文档作为rank list输入 
        * Listwise考虑序列整体，针对ranking评价指标进行优化
* **评价指标**
    * **MAP**
        * 假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1/1+2/2+3/4+4/7)/4=0.83。对于主题2，平均准确率为(1/1+2/3+3/5+0+0)/5=0.45。则MAP= (0.83+0.45)/2=0.64。
    * **NDCG**
        * 首先，Discounted cumulative gain （DCG）考量了 relevance judgment in terms of multiple ordered categories，以及对位置信息进行了折扣考量。定义 docs 排序列表 π 中位置 k 的 DCG 为
        ![](https://img-blog.csdn.net/20180519155635790?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpcGVuZ2Nu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
        * 其中，函数 G 是 对应 doc 的 rating 值，通常采用指数函数，如 G(x)=2^x-1，函数 η 即位置折扣因子，通常采用 η(j)=1/log(j+1)。 其次，对 DCG@k 进行归一化，规整到0-1，Z_k 表示 DCG@k 的可能最大值，从而有 NDCG 
        ![](https://img-blog.csdn.net/20180519160123480?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpcGVuZ2Nu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)
        * [计算公式](https://www.cnblogs.com/by-dream/p/9403984.html)
# RankNet、LambdaRank、LambdaMart
## RankNet
* pairwise训练方法，优化偏序关系
## LambdaRank
* Listwise训练方法，构造梯度，直接优化NDCG、MAP等不光滑的指标
## LambdaMart
* 基学习器是树模型，GBDT方式来构造梯度
    * 计算deltaNDCG，`$\lambda_{ij}=\rho_{ij}*|deltaNDCG(i,j)|$`以及lambda
    * 以lambda作为label训练一个regression tree
    *  在tree的每个叶子节点通过预测的regression lambda值还原出gamma，即最终输出得分；
    *  用3的模型预测所有训练集合上的得分`（+learningRate*gamma）`,然后用这个得分对每个query的结果排序，计算新的每个query的base ndcg，以此为基础回到第1步，组成森林。

# 达摩院Pre-train的数据是如何获得
* 合作方医院提供的5000W，医疗title-answer数据，不需要标注。

# 医疗的TS、AC数据是如何获得的
* 医疗的TS、AC数据是由所有网页的标注数据中筛选出来的，TS数据有11W左右 query-title对，AC数据有15W左右query-title对

# 为什么要标注TS、AC两批不同的数据
* TS标注数据只考虑query与title是否匹配，AC标注数据不但考虑query与title匹配程度，也会考虑content质量，以及网页排版等等。
* 主要是两种数据对应的下游任务不同，AC数据的下游任务是综合排序，TS数据则是文本分

# 为什么要用对抗训练
* 模型上线后，在线运行的时候，query可能会有错别字，表示不全等等情况，所以希望能够让模型对输入的扰动不敏感，也就是输入有变化时，模型的输出尽量保证不变，从而提高模型的鲁棒性和泛化能力
* 对抗训练思想总的来说就是，输入的时候进行梯度上升，loss优化参数的时候进行梯度下降
* 实际的做法就是在embedding 层进行梯度上升


# 召回策略
* 倒排索引
* 向量化召回